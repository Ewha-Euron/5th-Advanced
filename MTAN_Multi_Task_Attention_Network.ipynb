{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QvnFLRwPIBoUrVz2h2nerJgSX1M_XMhh",
      "authorship_tag": "ABX9TyOOAQREcMEgmP+ykInFe5Zn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/5th-Advanced/blob/1%EC%A3%BC%EC%B0%A8/MTAN_Multi_Task_Attention_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 이미지 간 회귀 작업**\n",
        "- 일대다 예측(One-to-many)"
      ],
      "metadata": {
        "id": "UXTLiBjcfNI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-1. 사용자 정의 모듈**"
      ],
      "metadata": {
        "id": "yDeiKUyUsKuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a) 데이터 생성**\n",
        "- 데이터 생성 과정"
      ],
      "metadata": {
        "id": "dYNqK4dWhHWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import Libraries\n",
        "\n",
        "import os\n",
        "import fnmatch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "dJ14qLdghOee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 이미지 데이터를 랜덤한 크기로 조절하고 보간하여 반환하는 클래스\n",
        "\n",
        "class RandomScaleCrop(object):\n",
        "  ## 초기화를 위한 함수\n",
        "  def __init__(self, scale=[1.0, 1.2, 1.5]):\n",
        "    self.scale = scale # 이미지 크기를 랜덤으로 조절하기 위해 스케일 리스트를 초기화\n",
        "\n",
        "  ## 콜백 함수\n",
        "  # 객체를 호출할 때 실행될 코드를 정의\n",
        "  def __call__(self, img, label, depth, normal):\n",
        "    height, width = img.shape[-2:] # 입력 이미지의 높이와 너비\n",
        "    sc = self.scale[random.randint(0, len(self.scale) - 1)] # 랜덤한 스케일 선택\n",
        "    h, w = int(height / sc), int(width / sc) # 높이와 너비를 새로 계산\n",
        "\n",
        "    # 이미지를 잘라낼 위치를 랜덤하게 선택\n",
        "    i = random.randint(0, height - h)\n",
        "    j = random.randint(0, width - w)\n",
        "\n",
        "    # 이미지 크기를 조절하고 보간(interpolation)\n",
        "    img_ = F.interpolate(img[None, :, i:i + h, j:j + w], size = (height, width),\n",
        "                         mode = 'bilinear', align_corners = True).squeeze(0)\n",
        "    # 라벨 데이터도 동일한 크기로 조절\n",
        "    label_ = F.interpolate(label[None, None, i:i + h, j:j + w], size = (height, width),\n",
        "                           mode = 'nearest').squeeze(0).squeeze(0)\n",
        "    # 깊이(depth) 데이터를 스케일에 맞게 조절\n",
        "    depth_ = F.interpolate(depth[None, :, i:i + h, j:j + w], size = (height, width), \\\n",
        "                           mode = 'nearest').squeeze(0) / sc\n",
        "\n",
        "    # 노멀(normal) 데이터도 크기를 조절하고 보간\n",
        "    normal_ = F.interpolate(normal[None, :, i:i + h, j:j + w], size = (height, width),\n",
        "                            mode = 'bilinear', align_corners = True).squeeze(0)\n",
        "\n",
        "    # 조절된 이미지, 라벨, 깊이, 노멀 데이터를 반환\n",
        "    return img_, label_, depth_, normal_"
      ],
      "metadata": {
        "id": "wYBdhnpvhYtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NYUv2 데이터셋 가공\n",
        "\n",
        "class NYUv2(Dataset):\n",
        "  \"\"\"\n",
        "  원본 논문에서는 데이터 증강(data augmentation)을 적용하지 않았다고 하지만, 우리는 NYUv2 데이터셋의 성능을 더 향상시키기 위해 다음과 같은 데이터 증강을 사용할 수 있다.\n",
        "  이 데이터 증강 기법은 아래 논문들에서 정의되어 있습니다:\n",
        "\n",
        "  1. 랜덤 스케일(Random Scale): 선택된 비율(1.0, 1.2, 1.5 중에서 랜덤하게 선택)로 이미지의 크기를 조절합니다.\n",
        "  2. 랜덤 수평 뒤집기(Random Horizontal Flip): 이미지를 수평 방향으로 랜덤하게 뒤집습니다.\n",
        "\n",
        "  이러한 데이터 증강 기법을 적용하면 모델의 성능을 향상시킬 수 있을 것으로 예상됩니다.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, root, train = True, augmentation = False):\n",
        "    self.train = train\n",
        "    self.root = os.path.expanduser(root)\n",
        "    self.augmentation = augmentation\n",
        "\n",
        "    # 데이터 파일 읽기\n",
        "    if train:\n",
        "        self.data_path = root + '/train'\n",
        "    else:\n",
        "        self.data_path = root + '/val'\n",
        "\n",
        "    # 데이터 길이 계산\n",
        "    self.data_len = len(fnmatch.filter(os.listdir(self.data_path + '/image'), '*.npy'))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    ## 미리 처리된 npy 파일에서 데이터 로드\n",
        "    image = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/image/{:d}.npy'.format(index)), -1, 0)) # 이미지\n",
        "    semantic = torch.from_numpy(np.load(self.data_path + '/label/{:d}.npy'.format(index))) # 시맨틱(객체 식별 정보)\n",
        "    depth = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/depth/{:d}.npy'.format(index)), -1, 0)) # 깊이\n",
        "    normal = torch.from_numpy(np.moveaxis(np.load(self.data_path + '/normal/{:d}.npy'.format(index)), -1, 0)) # 표면의 방향을 나타내는 벡터\n",
        "\n",
        "    ## 데이터 증강 적용 여부 확인\n",
        "    if self.augmentation:\n",
        "      # 랜덤 스케일과 크롭을 적용\n",
        "      image, semantic, depth, normal = RandomScaleCrop()(image, semantic, depth, normal)\n",
        "\n",
        "      # 50% 확률로 이미지를 수평으로 뒤집기\n",
        "      if torch.rand(1) < 0.5:\n",
        "        image = torch.flip(image, dims = [2])\n",
        "        semantic = torch.flip(semantic, dims = [1])\n",
        "        depth = torch.flip(depth, dims = [2])\n",
        "        normal = torch.flip(normal, dims = [2])\n",
        "        normal[0, :, :] = -normal[0, :, :]  # 노멀 벡터의 방향을 역전\n",
        "\n",
        "    return image.float(), semantic.float(), depth.float(), normal.float()\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data_len"
      ],
      "metadata": {
        "id": "VFqpDEHbjM3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b) utils**\n",
        "- task metrics, 손실함수, trainer 정의"
      ],
      "metadata": {
        "id": "fEOBsCxIsTaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1bKjbhKhug5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델 파라미터 개수를 세는 함수\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "W_MsXppXzriQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델의 예측과 정답 간의 손실을 계산하는 함수\n",
        "def model_fit(x_pred, x_output, task_type):\n",
        "  device = x_pred.device # 장치\n",
        "\n",
        "  ## 픽셀 공간을 마스킹하는 이진 mask\n",
        "  binary_mask = (torch.sum(x_output, dim = 1) != 0).float().unsqueeze(1).to(device)\n",
        "\n",
        "  ## 각 작업의 특징에 따라 다른 손실 함수 적용\n",
        "  if task_type == 'semantic':\n",
        "    # semantic loss: depth-wise cross entropy\n",
        "    loss = F.nll_loss(x_pred, x_output, ignore_index = -1) # Negative Log Likelihood\n",
        "  if task_type == 'depth':\n",
        "    # depth loss: L1 norm\n",
        "    loss = torch.sum(torch.abs(x_pred - x_output) * binary_mask) / torch.nonzero(binary_mask, as_tuple = False).size(0)\n",
        "  if task_type == 'normal':\n",
        "    # normal loss: dot product\n",
        "    loss = 1 - torch.sum((x_pred * x_output) * binary_mask) / torch.nonzero(binary_mask, as_tuple = False).size(0)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "VQUM5sjRzhn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델의 분류 결과와 실제 레이블 간의 혼동 행렬(Confusion Matrix)을 계산하고 관련된 분류 메트릭을 계산\n",
        "class ConfMatrix(object):\n",
        "  ## 클래스를 초기화하는 생성자\n",
        "  def __init__(self, num_classes):\n",
        "    self.num_classes = num_classes\n",
        "    self.mat = None\n",
        "\n",
        "  ## 모델의 예측 (pred)과 실제 레이블 (target)을 입력으로 받아 혼동 행렬을 업데이트\n",
        "  def update(self, pred, target):\n",
        "    n = self.num_classes\n",
        "    if self.mat is None:\n",
        "      self.mat = torch.zeros((n, n), dtype=torch.int64, device = pred.device)\n",
        "    with torch.no_grad():\n",
        "      # 정상 범위 내의 레이블과 예측을 선택\n",
        "      k = (target >= 0) & (target < n)\n",
        "      # 인덱스 계산\n",
        "      inds = n * target[k].to(torch.int64) + pred[k]\n",
        "      # 혼동 행렬 업데이트\n",
        "      self.mat += torch.bincount(inds, minlength = n ** 2).reshape(n, n)\n",
        "\n",
        "  ## 업데이트된 혼동 행렬을 기반으로 분류 메트릭을 계산\n",
        "  def get_metrics(self):\n",
        "    h = self.mat.float()\n",
        "    acc = torch.diag(h).sum() / h.sum() # 정확도\n",
        "    iu = torch.diag(h) / (h.sum(1) + h.sum(0) - torch.diag(h)) # IoU (Intersection over Union)\n",
        "    return torch.mean(iu).item(), acc.item()"
      ],
      "metadata": {
        "id": "bXUxXyN0zuXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 깊이(depth) 예측 모델의 오차를 계산하는 함수\n",
        "def depth_error(x_pred, x_output):\n",
        "  device = x_pred.device\n",
        "  ## 정의되지 않은 영역을 이진 마스크로 설정\n",
        "  binary_mask = (torch.sum(x_output, dim=1) != 0).unsqueeze(1).to(device)\n",
        "\n",
        "  ## 이진 마스크를 사용하여 정의된 영역에서 예측 값과 실제 값 추출\n",
        "  x_pred_true = x_pred.masked_select(binary_mask)\n",
        "  x_output_true = x_output.masked_select(binary_mask)\n",
        "\n",
        "  ## 절대 오차 및 상대 오차 계산\n",
        "  abs_err = torch.abs(x_pred_true - x_output_true)\n",
        "  rel_err = torch.abs(x_pred_true - x_output_true) / x_output_true\n",
        "\n",
        "  ## 평균 오차 반환\n",
        "  return (torch.sum(abs_err) / torch.nonzero(binary_mask, as_tuple=False).size(0)).item(), \\\n",
        "          (torch.sum(rel_err) / torch.nonzero(binary_mask, as_tuple=False).size(0)).item()"
      ],
      "metadata": {
        "id": "l2DI3gOqz31Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 표면 normal 예측 모델의 오차를 계산하는 함수\n",
        "def normal_error(x_pred, x_output):\n",
        "  binary_mask = (torch.sum(x_output, dim = 1) != 0)\n",
        "  error = torch.acos(torch.clamp(torch.sum(x_pred * x_output, 1).masked_select(binary_mask), -1, 1)).detach().cpu().numpy()\n",
        "  error = np.degrees(error)\n",
        "  return np.mean(error), np.median(error), np.mean(error < 11.25), np.mean(error < 22.5), np.mean(error < 30)"
      ],
      "metadata": {
        "id": "MpRxPaIWz42R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Multi-task모델을 훈련하는 함수\n",
        "def multi_task_trainer(train_loader, test_loader, multi_task_model, device, optimizer, scheduler, opt, total_epoch=200):\n",
        "  train_batch = len(train_loader)\n",
        "  test_batch = len(test_loader)\n",
        "  avg_cost = np.zeros([total_epoch, 24], dtype = np.float32)\n",
        "  lambda_weight = np.ones([3, total_epoch])\n",
        "  for index in range(total_epoch):\n",
        "    cost = np.zeros(24, dtype=np.float32) # 비용\n",
        "\n",
        "    ## Dynamic Weight Average(DWA) 적용\n",
        "    # 각 작업의 손실 변화율을 고려하여 시간에 따라 작업 가중치를 평균화하는 방법\n",
        "    if opt.weight == 'dwa':\n",
        "      if index == 0 or index == 1:\n",
        "        lambda_weight[:, index] = 1.0\n",
        "      else:\n",
        "        w_1 = avg_cost[index - 1, 0] / avg_cost[index - 2, 0]\n",
        "        w_2 = avg_cost[index - 1, 3] / avg_cost[index - 2, 3]\n",
        "        w_3 = avg_cost[index - 1, 6] / avg_cost[index - 2, 6]\n",
        "        lambda_weight[0, index] = 3 * np.exp(w_1 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
        "        lambda_weight[1, index] = 3 * np.exp(w_2 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
        "        lambda_weight[2, index] = 3 * np.exp(w_3 / T) / (np.exp(w_1 / T) + np.exp(w_2 / T) + np.exp(w_3 / T))\n",
        "\n",
        "    ## 모든 batch에 대해 반복\n",
        "    # 학습\n",
        "    multi_task_model.train()\n",
        "    train_dataset = iter(train_loader)\n",
        "    # 오차 행렬\n",
        "    conf_mat = ConfMatrix(multi_task_model.class_nb)\n",
        "\n",
        "    for k in range(train_batch):\n",
        "      train_data, train_label, train_depth, train_normal = next(train_dataset)\n",
        "      train_data, train_label = train_data.to(device), train_label.long().to(device)\n",
        "      train_depth, train_normal = train_depth.to(device), train_normal.to(device)\n",
        "\n",
        "      train_pred, logsigma = multi_task_model(train_data)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_loss = [model_fit(train_pred[0], train_label, 'semantic'),\n",
        "                    model_fit(train_pred[1], train_depth, 'depth'),\n",
        "                    model_fit(train_pred[2], train_normal, 'normal')]\n",
        "\n",
        "      # 손실 계산\n",
        "      if opt.weight == 'equal' or opt.weight == 'dwa':\n",
        "        loss = sum([lambda_weight[i, index] * train_loss[i] for i in range(3)])\n",
        "      else:\n",
        "        loss = sum(1 / (2 * torch.exp(logsigma[i])) * train_loss[i] + logsigma[i] / 2 for i in range(3))\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # 훈련 이미지의 각 픽셀에서 레이블 예측을 누적\n",
        "      conf_mat.update(train_pred[0].argmax(1).flatten(), train_label.flatten())\n",
        "\n",
        "      # 비용 계산\n",
        "      cost[0] = train_loss[0].item()\n",
        "      cost[3] = train_loss[1].item()\n",
        "      cost[4], cost[5] = depth_error(train_pred[1], train_depth)\n",
        "      cost[6] = train_loss[2].item()\n",
        "      cost[7], cost[8], cost[9], cost[10], cost[11] = normal_error(train_pred[2], train_normal)\n",
        "      avg_cost[index, :12] += cost[:12] / train_batch\n",
        "\n",
        "    # mIoU와 Acc 계산\n",
        "    avg_cost[index, 1:3] = np.array(conf_mat.get_metrics())\n",
        "\n",
        "    ## test 데이터에 대한 평가\n",
        "    multi_task_model.eval()\n",
        "    conf_mat = ConfMatrix(multi_task_model.class_nb) # 오차 행렬\n",
        "    with torch.no_grad():  # operations inside don't track history\n",
        "      test_dataset = iter(test_loader)\n",
        "      for k in range(test_batch):\n",
        "        test_data, test_label, test_depth, test_normal = next(test_dataset)\n",
        "        test_data, test_label = test_data.to(device), test_label.long().to(device)\n",
        "        test_depth, test_normal = test_depth.to(device), test_normal.to(device)\n",
        "\n",
        "        test_pred, _ = multi_task_model(test_data)\n",
        "        test_loss = [model_fit(test_pred[0], test_label, 'semantic'),\n",
        "                      model_fit(test_pred[1], test_depth, 'depth'),\n",
        "                      model_fit(test_pred[2], test_normal, 'normal')]\n",
        "\n",
        "        conf_mat.update(test_pred[0].argmax(1).flatten(), test_label.flatten())\n",
        "\n",
        "        cost[12] = test_loss[0].item()\n",
        "        cost[15] = test_loss[1].item()\n",
        "        cost[16], cost[17] = depth_error(test_pred[1], test_depth)\n",
        "        cost[18] = test_loss[2].item()\n",
        "        cost[19], cost[20], cost[21], cost[22], cost[23] = normal_error(test_pred[2], test_normal)\n",
        "        avg_cost[index, 12:] += cost[12:] / test_batch\n",
        "\n",
        "      # mIoU와 Acc 계산\n",
        "      avg_cost[index, 13:15] = np.array(conf_mat.get_metrics())\n",
        "\n",
        "    scheduler.step()\n",
        "    print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} ||'\n",
        "        'TEST: {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} | {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} '\n",
        "        .format(index, avg_cost[index, 0], avg_cost[index, 1], avg_cost[index, 2], avg_cost[index, 3],\n",
        "                avg_cost[index, 4], avg_cost[index, 5], avg_cost[index, 6], avg_cost[index, 7], avg_cost[index, 8],\n",
        "                avg_cost[index, 9], avg_cost[index, 10], avg_cost[index, 11], avg_cost[index, 12], avg_cost[index, 13],\n",
        "                avg_cost[index, 14], avg_cost[index, 15], avg_cost[index, 16], avg_cost[index, 17], avg_cost[index, 18],\n",
        "                avg_cost[index, 19], avg_cost[index, 20], avg_cost[index, 21], avg_cost[index, 22], avg_cost[index, 23]))"
      ],
      "metadata": {
        "id": "n0Ox_X5AsVy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Single-task 모델을 훈련하는 함수\n",
        "## multi_task_trainer와 비슷하지만 single task에 맞게 설정\n",
        "\n",
        "def single_task_trainer(train_loader, test_loader, single_task_model, device, optimizer, scheduler, opt, total_epoch=200):\n",
        "    train_batch = len(train_loader)\n",
        "    test_batch = len(test_loader)\n",
        "    avg_cost = np.zeros([total_epoch, 24], dtype=np.float32)\n",
        "    for index in range(total_epoch):\n",
        "        cost = np.zeros(24, dtype=np.float32)\n",
        "\n",
        "        # iteration for all batches\n",
        "        single_task_model.train()\n",
        "        train_dataset = iter(train_loader)\n",
        "        conf_mat = ConfMatrix(single_task_model.class_nb)\n",
        "        for k in range(train_batch):\n",
        "            train_data, train_label, train_depth, train_normal = next(train_dataset)\n",
        "            train_data, train_label = train_data.to(device), train_label.long().to(device)\n",
        "            train_depth, train_normal = train_depth.to(device), train_normal.to(device)\n",
        "\n",
        "            train_pred = single_task_model(train_data)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if opt.task == 'semantic':\n",
        "                train_loss = model_fit(train_pred, train_label, opt.task)\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                conf_mat.update(train_pred.argmax(1).flatten(), train_label.flatten())\n",
        "                cost[0] = train_loss.item()\n",
        "\n",
        "            if opt.task == 'depth':\n",
        "                train_loss = model_fit(train_pred, train_depth, opt.task)\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "                cost[3] = train_loss.item()\n",
        "                cost[4], cost[5] = depth_error(train_pred, train_depth)\n",
        "\n",
        "            if opt.task == 'normal':\n",
        "                train_loss = model_fit(train_pred, train_normal, opt.task)\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "                cost[6] = train_loss.item()\n",
        "                cost[7], cost[8], cost[9], cost[10], cost[11] = normal_error(train_pred, train_normal)\n",
        "\n",
        "            avg_cost[index, :12] += cost[:12] / train_batch\n",
        "\n",
        "        if opt.task == 'semantic':\n",
        "            avg_cost[index, 1:3] = np.array(conf_mat.get_metrics())\n",
        "\n",
        "        # evaluating test data\n",
        "        single_task_model.eval()\n",
        "        conf_mat = ConfMatrix(single_task_model.class_nb)\n",
        "        with torch.no_grad():  # operations inside don't track history\n",
        "            test_dataset = iter(test_loader)\n",
        "            for k in range(test_batch):\n",
        "                test_data, test_label, test_depth, test_normal = next(test_dataset)\n",
        "                test_data, test_label = test_data.to(device),  test_label.long().to(device)\n",
        "                test_depth, test_normal = test_depth.to(device), test_normal.to(device)\n",
        "\n",
        "                test_pred = single_task_model(test_data)\n",
        "\n",
        "                if opt.task == 'semantic':\n",
        "                    test_loss = model_fit(test_pred, test_label, opt.task)\n",
        "\n",
        "                    conf_mat.update(test_pred.argmax(1).flatten(), test_label.flatten())\n",
        "                    cost[12] = test_loss.item()\n",
        "\n",
        "                if opt.task == 'depth':\n",
        "                    test_loss = model_fit(test_pred, test_depth, opt.task)\n",
        "                    cost[15] = test_loss.item()\n",
        "                    cost[16], cost[17] = depth_error(test_pred, test_depth)\n",
        "\n",
        "                if opt.task == 'normal':\n",
        "                    test_loss = model_fit(test_pred, test_normal, opt.task)\n",
        "                    cost[18] = test_loss.item()\n",
        "                    cost[19], cost[20], cost[21], cost[22], cost[23] = normal_error(test_pred, test_normal)\n",
        "\n",
        "                avg_cost[index, 12:] += cost[12:] / test_batch\n",
        "            if opt.task == 'semantic':\n",
        "                avg_cost[index, 13:15] = np.array(conf_mat.get_metrics())\n",
        "\n",
        "        scheduler.step()\n",
        "        if opt.task == 'semantic':\n",
        "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f}'\n",
        "              .format(index, avg_cost[index, 0], avg_cost[index, 1], avg_cost[index, 2], avg_cost[index, 12], avg_cost[index, 13], avg_cost[index, 14]))\n",
        "        if opt.task == 'depth':\n",
        "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f}'\n",
        "              .format(index, avg_cost[index, 3], avg_cost[index, 4], avg_cost[index, 5], avg_cost[index, 15], avg_cost[index, 16], avg_cost[index, 17]))\n",
        "        if opt.task == 'normal':\n",
        "            print('Epoch: {:04d} | TRAIN: {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} TEST: {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'\n",
        "              .format(index, avg_cost[index, 6], avg_cost[index, 7], avg_cost[index, 8], avg_cost[index, 9], avg_cost[index, 10], avg_cost[index, 11],\n",
        "                      avg_cost[index, 18], avg_cost[index, 19], avg_cost[index, 20], avg_cost[index, 21], avg_cost[index, 22], avg_cost[index, 23]))"
      ],
      "metadata": {
        "id": "TRrLAuPb7iw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-2. 실험**"
      ],
      "metadata": {
        "id": "CcUlj-vCob3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 사용자 정의 모듈 불러오기\n",
        "# 매번 실행해 주어야 함\n",
        "\n",
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('create_dataset.py','wb').write(src)"
      ],
      "metadata": {
        "id": "ldCbU4c3qifo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('utils.py','wb').write(src)"
      ],
      "metadata": {
        "id": "zB2xoF05rpf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a) 단일 작업, 하나의 작업(Single-Task, One Task)**\n",
        "- 단일 작업 학습을 위한 기본 SegNet"
      ],
      "metadata": {
        "id": "FrsdO0yootAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import Libraries\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "\n",
        "# 사용자 정의 모듈\n",
        "from create_dataset import *\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "d-lU6WTdo_jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 명령행 인수파싱\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "# 명령행 인수를 리스트로 지정\n",
        "sys.argv = ['program_name', '--task', 'depth', '--dataroot', 'nyuv2', '--apply_augmentation']\n",
        "\n",
        "# ArgumentParser 생성\n",
        "parser = argparse.ArgumentParser(description='Single-task: One Task')\n",
        "\n",
        "# task 옵션 설정 (기본값은 'semantic')\n",
        "parser.add_argument('--task', default='semantic', type=str, help='choose task: semantic, depth, normal')\n",
        "\n",
        "# dataroot 옵션 설정 (기본값은 'nyuv2')\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "\n",
        "# apply_augmentation 플래그 설정 (True로 설정하면 데이터 증강이 적용됨)\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "\n",
        "# 명령행 인수 파싱\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "qrhhBV7N8mka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNet(nn.Module):\n",
        "    ### 초기화 함수\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        ## initialise network parameters: 네트워크 파라미터 초기화\n",
        "        filter = [64, 128, 256, 512, 512]  # 필터 크기 정의\n",
        "        self.class_nb = 13  # 클래스 수\n",
        "\n",
        "        ## define encoder decoder layers: 인코더 및 디코더 레이어 정의\n",
        "        self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0]])])  # 인코더 블록 초기화\n",
        "        self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])  # 디코더 블록 초기화\n",
        "        for i in range(4):\n",
        "            self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1]]))  # 인코더 블록 추가\n",
        "            self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i]]))  # 디코더 블록 추가\n",
        "\n",
        "        ## define convolution layer: 컨볼루션 레이어 정의\n",
        "        self.conv_block_enc = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])  # 인코더 컨볼루션 레이어 초기화\n",
        "        self.conv_block_dec = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])  # 디코더 컨볼루션 레이어 초기화\n",
        "        for i in range(4):\n",
        "            if i == 0:\n",
        "                self.conv_block_enc.append(self.conv_layer([filter[i + 1], filter[i + 1]]))  # 인코더 컨볼루션 레이어 추가\n",
        "                self.conv_block_dec.append(self.conv_layer([filter[i], filter[i]]))  # 디코더 컨볼루션 레이어 추가\n",
        "            else:\n",
        "                # 두 개의 컨볼루션 레이어를 가진 시퀀셜 블록 추가\n",
        "                self.conv_block_enc.append(nn.Sequential(self.conv_layer([filter[i + 1], filter[i + 1]]),\n",
        "                                                         self.conv_layer([filter[i + 1], filter[i + 1]])))\n",
        "                self.conv_block_dec.append(nn.Sequential(self.conv_layer([filter[i], filter[i]]),\n",
        "                                                         self.conv_layer([filter[i], filter[i]])))\n",
        "\n",
        "        ## 예측 레이어 정의\n",
        "        if opt.task == 'semantic':\n",
        "            self.pred_task = self.conv_layer([filter[0], self.class_nb], pred=True)  # 클래스별 예측 레이어\n",
        "        if opt.task == 'depth':\n",
        "            self.pred_task = self.conv_layer([filter[0], 1], pred=True)  # 깊이 예측 레이어\n",
        "        if opt.task == 'normal':\n",
        "            self.pred_task = self.conv_layer([filter[0], 3], pred=True)  # 법선(normal) 벡터 예측 레이어\n",
        "\n",
        "        ## define pooling and unpooling functions: 풀링 및 언풀링 함수 정의\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)  # 다운 샘플링 함수\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)  # 업 샘플링 함수\n",
        "\n",
        "        ## 네트워크 모듈 초기화\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d): # 합성곱 층\n",
        "                nn.init.xavier_normal_(m.weight)  # 컨볼루션 레이어 가중치 초기화\n",
        "                nn.init.constant_(m.bias, 0)  # 컨볼루션 레이어 편향 초기화\n",
        "            elif isinstance(m, nn.BatchNorm2d): # 배치 정규화 층\n",
        "                nn.init.constant_(m.weight, 1)  # 배치 정규화 가중치 초기화\n",
        "                nn.init.constant_(m.bias, 0)  # 배치 정규화 편향 초기화\n",
        "            elif isinstance(m, nn.Linear): # 선형 층\n",
        "                nn.init.xavier_normal_(m.weight)  # 선형 레이어 가중치 초기화\n",
        "                nn.init.constant_(m.bias, 0)  # 선형 레이어 편향 초기화\n",
        "\n",
        "    ## 컨볼루션 레이어 생성 함수\n",
        "    def conv_layer(self, channel, pred=False):\n",
        "        if not pred:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),  # 컨볼루션 레이어\n",
        "                nn.BatchNorm2d(num_features=channel[1]),  # 배치 정규화\n",
        "                nn.ReLU(inplace=True),  # ReLU 활성화 함수\n",
        "            )\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            )\n",
        "        return conv_block\n",
        "\n",
        "    ### 순방향 전달 함수\n",
        "    def forward(self, x):\n",
        "        g_encoder, g_decoder, g_maxpool, g_upsampl, indices = ([0] * 5 for _ in range(5))\n",
        "        for i in range(5):\n",
        "            g_encoder[i], g_decoder[-i - 1] = ([0] * 2 for _ in range(2))\n",
        "\n",
        "        ## 공유 네트워크 정의\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_encoder[i][0] = self.encoder_block[i](x)\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "            else:\n",
        "                g_encoder[i][0] = self.encoder_block[i](g_maxpool[i - 1])\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_upsampl[i] = self.up_sampling(g_maxpool[-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "            else:\n",
        "                g_upsampl[i] = self.up_sampling(g_decoder[i - 1][-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "\n",
        "        ## 작업 예측 레이어 정의 (semantic, depth, normal)\n",
        "        if opt.task == 'semantic':\n",
        "            pred = F.log_softmax(self.pred_task(g_decoder[-1][-1]), dim=1)  # semantic segmentation 예측\n",
        "        if opt.task == 'depth':\n",
        "            pred = self.pred_task(g_decoder[-1][-1])  # 깊이 예측\n",
        "        if opt.task == 'normal':\n",
        "            pred = self.pred_task(g_decoder[-1][-1])  # 법선 벡터 예측\n",
        "            pred = pred / torch.norm(pred, p=2, dim=1, keepdim=True)  # 법선 벡터 정규화\n",
        "        return pred"
      ],
      "metadata": {
        "id": "RZ7e6oRFo6tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델, 옵티마이저 및 스케줄러 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # GPU 또는 CPU 장치 선택\n",
        "SegNet = SegNet().to(device)  # SegNet 모델 초기화 및 장치 설정\n",
        "optimizer = optim.Adam(SegNet.parameters(), lr=1e-4)  # Adam 옵티마이저 초기화\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)  # 학습률 스케줄러 설정\n",
        "\n",
        "# 네트워크의 파라미터 공간 크기 출력\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet),\n",
        "                                                         count_parameters(SegNet) / 24981069))\n",
        "\n",
        "# 출력 형식 정의\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')"
      ],
      "metadata": {
        "id": "3McTVAkACTn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터셋 및 데이터로더 설정\n",
        "dataset_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Euron 5기/Week 1/im2im_pred', opt.dataroot)  # 데이터셋 경로\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)  # 데이터 증강 적용\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)  # 표준 훈련 전략\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)  # 테스트 데이터셋"
      ],
      "metadata": {
        "id": "yYxSu10iCc4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2  # 배치 크기 설정\n",
        "\n",
        "## 훈련 데이터로더 설정\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = nyuv2_train_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True)\n",
        "\n",
        "## 테스트 데이터로더 설정\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = nyuv2_test_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False)\n",
        "\n",
        "## Single-task 네트워크 훈련 및 평가\n",
        "# 200 에폭 동안 훈련\n",
        "single_task_trainer(nyuv2_train_loader,\n",
        "                    nyuv2_test_loader,\n",
        "                    SegNet,\n",
        "                    device,\n",
        "                    optimizer,\n",
        "                    scheduler,\n",
        "                    opt,\n",
        "                    200)"
      ],
      "metadata": {
        "id": "8IqJMXh8DBKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시간이 오래 걸려서 실행해보지는 x"
      ],
      "metadata": {
        "id": "3eebmkUbl1S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b) 단일 작업, STAN**\n",
        "- Single-Task Attention Network\n",
        "- 단일 작업만 수행하면서 제안된 MTAN을 직접 적용한 **단일** 작업 주의 네트워크"
      ],
      "metadata": {
        "id": "hRlXIefWl5MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Import Libraries\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "\n",
        "from create_dataset import *\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "8m7hBwQFnw5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 명령행 인수 파싱\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "## 명령행 인수를 리스트로 지정\n",
        "sys.argv = ['program_name', '--task', 'depth', '--dataroot', 'nyuv2', '--apply_augmentation']\n",
        "\n",
        "## 명령행 인수를 파싱할 파서(parser) 설정\n",
        "parser = argparse.ArgumentParser(description = 'Single-task: Attention Network')\n",
        "\n",
        "## add_argument 메서드를 사용하여 프로그램에 전달될 명령행 인수를 정의\n",
        "# 기본값: 'semantic'\n",
        "parser.add_argument('--task', default='semantic', type=str, help='choose task: semantic, depth, normal')\n",
        "\n",
        "## '--dataroot': 기본값은 'nyuv2'\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "\n",
        "## '--apply_augmentation': 지정되면 True, 그렇지 않으면 False로 설정\n",
        "# action='store_true': 인수를 받지 않고 해당 옵션을 사용하면 True로 설정\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "\n",
        "## 명령행 인수를 파싱하고, 그 결과를 opt 객체에 저장\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "pE-26p6Sn95C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SegNet 모델 정의\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "  ## 신경망 레이어 및 파라미터 초기화\n",
        "  def __init__(self):\n",
        "    super(SegNet, self).__init__() # nn.Module 클래스를 상속하여 신경망 아키텍처를 정의\n",
        "    # 네트워크 매개변수 초기화\n",
        "    filter = [64, 128, 256, 512, 512] # 인코더와 디코더 레이어의 출력 채널 수\n",
        "    self.class_nb = 13  # 세그멘테이션 작업에서 구분할 클래스 수\n",
        "\n",
        "    # 인코더/디코더 레이어 정의\n",
        "    self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0]])])\n",
        "    self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "    for i in range(4):\n",
        "      self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1]]))\n",
        "      self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "\n",
        "    self.conv_block_enc = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "    self.conv_block_dec = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "    for i in range(4):\n",
        "      if i == 0:\n",
        "        self.conv_block_enc.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "        self.conv_block_dec.append(self.conv_layer([filter[i], filter[i]]))\n",
        "      else:\n",
        "        self.conv_block_enc.append(nn.Sequential(self.conv_layer([filter[i + 1], filter[i + 1]]),\n",
        "                                                self.conv_layer([filter[i + 1], filter[i + 1]])))\n",
        "        self.conv_block_dec.append(nn.Sequential(self.conv_layer([filter[i], filter[i]]),\n",
        "                                                self.conv_layer([filter[i], filter[i]])))\n",
        "    # 어텐션(attention) 레이어\n",
        "    # 입력 데이터의 중요한 부분에 가중치를 부여하여 어텐션 메커니즘을 구현\n",
        "    self.encoder_att = nn.ModuleList([nn.ModuleList([self.att_layer([filter[0], filter[0], filter[0]])])])\n",
        "    self.decoder_att = nn.ModuleList([nn.ModuleList([self.att_layer([2 * filter[0], filter[0], filter[0]])])])\n",
        "    self.encoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[1]])])\n",
        "    self.decoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "\n",
        "    for j in range(1):\n",
        "      for i in range(4):\n",
        "        self.encoder_att[j].append(self.att_layer([2 * filter[i + 1], filter[i + 1], filter[i + 1]]))\n",
        "        self.decoder_att[j].append(self.att_layer([filter[i + 1] + filter[i], filter[i], filter[i]]))\n",
        "    for i in range(4):\n",
        "      if i < 3:\n",
        "        self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 2]]))\n",
        "        self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "      else:\n",
        "        self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "        self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "\n",
        "    # 최종 출력 레이어\n",
        "    # 작업 종류(opt.task)에 따라 예측 레이어를 정의\n",
        "    if opt.task == 'semantic':\n",
        "      self.pred_task = self.conv_layer([filter[0], self.class_nb], pred=True)\n",
        "    if opt.task == 'depth':\n",
        "      self.pred_task = self.conv_layer([filter[0], 1], pred=True)\n",
        "    if opt.task == 'normal':\n",
        "      self.pred_task = self.conv_layer([filter[0], 3], pred=True)\n",
        "\n",
        "    # 풀링 및 언풀링 함수 정의\n",
        "    self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "    self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # 가중치 초기화\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    # 컨볼루션 레이어와 배치 정규화 레이어를 포함하는 Sequential 모듈을 정의\n",
        "    def conv_layer(self, channel, pred=False):\n",
        "      if not pred:\n",
        "        conv_block = nn.Sequential(\n",
        "          # 2D 컨볼루션 레이어를 생성하며, 입력 채널에서 출력 채널로 변환\n",
        "          nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "          # 배치 정규화 적용\n",
        "          nn.BatchNorm2d(num_features=channel[1]),\n",
        "          # ReLU 활성화 함수를 적용\n",
        "          nn.ReLU(inplace=True),\n",
        "        )\n",
        "      else:\n",
        "        conv_block = nn.Sequential(\n",
        "          # 예측 모드인 경우 입력 채널과 출력 채널이 동일한 2D 컨볼루션 레이어 생성\n",
        "          nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "          # 추가적인 1x1 컨볼루션 레이어를 사용하여 출력 채널을 변경\n",
        "          nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "        )\n",
        "      return conv_block\n",
        "\n",
        "      def att_layer(self, channel):\n",
        "        # 어텐션 레이어를 포함하는 Sequential 모듈을 정의\n",
        "        att_block = nn.Sequential(\n",
        "          # 1x1 컨볼루션 레이어를 사용하여 입력 채널에서 출력 채널로 변환\n",
        "          nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "          # 배치 정규화를 적용\n",
        "          nn.BatchNorm2d(channel[1]),\n",
        "          # ReLU 활성화 함수를 적용\n",
        "          nn.ReLU(inplace=True),\n",
        "          # 1x1 컨볼루션 레이어를 사용하여 출력 채널을 다시 변경\n",
        "          nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=1, padding=0),\n",
        "          # 시그모이드 활성화 함수를 적용\n",
        "          nn.BatchNorm2d(channel[2]),\n",
        "          nn.Sigmoid(),\n",
        "        )\n",
        "        return att_block\n",
        "\n",
        "  ## 순전파\n",
        "  def forward(self, x):\n",
        "    # 초기 변수 정의\n",
        "    g_encoder, g_decoder, g_maxpool, g_upsampl, indices = ([0] * 5 for _ in range(5))\n",
        "    for i in range(5):\n",
        "      g_encoder[i], g_decoder[-i - 1] = ([0] * 2 for _ in range(2))\n",
        "    # 두 가지 작업에 대한 주의 목록 정의\n",
        "    atten_encoder, atten_decoder = ([0] * 3 for _ in range(2))\n",
        "    for i in range(3):\n",
        "      atten_encoder[i], atten_decoder[i] = ([0] * 5 for _ in range(2))\n",
        "    for i in range(3):\n",
        "      for j in range(5):\n",
        "        atten_encoder[i][j], atten_decoder[i][j] = ([0] * 3 for _ in range(2))\n",
        "\n",
        "    # 전역 공유 네트워크 정의\n",
        "    # 전역 공유 네트워크의 인코더 부분을 정의하고 풀링 연산을 수행\n",
        "    for i in range(5):\n",
        "      if i == 0:\n",
        "        g_encoder[i][0] = self.encoder_block[i](x)\n",
        "        g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "        g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "      else:\n",
        "        g_encoder[i][0] = self.encoder_block[i](g_maxpool[i - 1])\n",
        "        g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "        g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "    for i in range(5):\n",
        "      if i == 0:\n",
        "        g_upsampl[i] = self.up_sampling(g_maxpool[-1], indices[-i - 1])\n",
        "        g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "        g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "      else:\n",
        "        g_upsampl[i] = self.up_sampling(g_decoder[i - 1][-1], indices[-i - 1])\n",
        "        g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "        g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "\n",
        "    # 작업 종속 주의 모듈 정의\n",
        "    # 주의 메커니즘을 사용하여 인코더 및 디코더의 출력을 가중치화하고 주의 적용 결과를 계산\n",
        "    for i in range(1):\n",
        "      for j in range(5):\n",
        "        if j == 0:\n",
        "          atten_encoder[i][j][0] = self.encoder_att[i][j](g_encoder[j][0])\n",
        "          atten_encoder[i][j][1] = (atten_encoder[i][j][0]) * g_encoder[j][1]\n",
        "          atten_encoder[i][j][2] = self.encoder_block_att[j](atten_encoder[i][j][1])\n",
        "          atten_encoder[i][j][2] = F.max_pool2d(atten_encoder[i][j][2], kernel_size=2, stride=2)\n",
        "        else:\n",
        "          atten_encoder[i][j][0] = self.encoder_att[i][j](torch.cat((g_encoder[j][0], atten_encoder[i][j - 1][2]), dim=1))\n",
        "          atten_encoder[i][j][1] = (atten_encoder[i][j][0]) * g_encoder[j][1]\n",
        "          atten_encoder[i][j][2] = self.encoder_block_att[j](atten_encoder[i][j][1])\n",
        "          atten_encoder[i][j][2] = F.max_pool2d(atten_encoder[i][j][2], kernel_size=2, stride=2)\n",
        "\n",
        "      for j in range(5):\n",
        "        if j == 0:\n",
        "          atten_decoder[i][j][0] = F.interpolate(atten_encoder[i][-1][-1], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "          atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "          atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "          atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "        else:\n",
        "          atten_decoder[i][j][0] = F.interpolate(atten_decoder[i][j - 1][2], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "          atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "          atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "          atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "\n",
        "    # 작업 예측 레이어 정의\n",
        "    if opt.task == 'semantic':\n",
        "      pred = F.log_softmax(self.pred_task(atten_decoder[0][-1][-1]), dim=1)\n",
        "    if opt.task == 'depth':\n",
        "      pred = self.pred_task(atten_decoder[0][-1][-1])\n",
        "    if opt.task == 'normal':\n",
        "      pred = self.pred_task(atten_decoder[0][-1][-1])\n",
        "      pred = pred / torch.norm(pred, p=2, dim=1, keepdim=True)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "7B6ajRGUmM8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 레이어 넘어갈 때 인덱스 붙이는 게 이해되지 않는다..하하.."
      ],
      "metadata": {
        "id": "SoCaanO9xWLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델, 옵티마이저 및 스케줄러 정의\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_STAN = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_STAN.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "# 모델 파라미터 개수 출력\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_STAN),\n",
        "                                                         count_parameters(SegNet_STAN) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')"
      ],
      "metadata": {
        "id": "s89bPsU_yeTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터셋 정의\n",
        "dataset_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Euron 5기/Week 1/im2im_pred', opt.dataroot)  # 데이터셋 경로\n",
        "\n",
        "## 데이터 증강 여부에 따라 데이터셋 설정\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)"
      ],
      "metadata": {
        "id": "GUbWKxglo2wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "iGXB8vLJy4OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Single-task 네트워크 훈련 및 평가\n",
        "single_task_trainer(nyuv2_train_loader,\n",
        "                    nyuv2_test_loader,\n",
        "                    SegNet_STAN,\n",
        "                    device,\n",
        "                    optimizer,\n",
        "                    scheduler,\n",
        "                    opt,\n",
        "                    200)"
      ],
      "metadata": {
        "id": "5E-MQxEeyr8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c) 다중 작업, 분할(Multi-Task, Split-Wide, Deep)**\n",
        "- 각 특정 작업에 대한 최종 예측을 위해 마지막 레이어에서 분할하는 표준 다중 작업 학습\n"
      ],
      "metadata": {
        "id": "4uRnCxI6zCaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "from create_dataset import *\n",
        "from utils import *\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Multi-task: Split')\n",
        "parser.add_argument('--type', default='standard', type=str, help='split type: standard, wide, deep')\n",
        "parser.add_argument('--weight', default='equal', type=str, help='multi-task weighting: equal, uncert, dwa')\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "parser.add_argument('--temp', default=2.0, type=float, help='temperature for DWA (must be positive)')\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        # initialise network parameters\n",
        "        if opt.type == 'wide':\n",
        "            filter = [64, 128, 256, 512, 1024]\n",
        "        else:\n",
        "            filter = [64, 128, 256, 512, 512]\n",
        "\n",
        "        self.class_nb = 13\n",
        "\n",
        "        # define encoder decoder layers\n",
        "        self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0]])])\n",
        "        self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        for i in range(4):\n",
        "            self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1]]))\n",
        "            self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "\n",
        "        # define convolution layer\n",
        "        self.conv_block_enc = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        self.conv_block_dec = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        for i in range(4):\n",
        "            if i == 0:\n",
        "                self.conv_block_enc.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "                self.conv_block_dec.append(self.conv_layer([filter[i], filter[i]]))\n",
        "            else:\n",
        "                self.conv_block_enc.append(nn.Sequential(self.conv_layer([filter[i + 1], filter[i + 1]]),\n",
        "                                                         self.conv_layer([filter[i + 1], filter[i + 1]])))\n",
        "                self.conv_block_dec.append(nn.Sequential(self.conv_layer([filter[i], filter[i]]),\n",
        "                                                         self.conv_layer([filter[i], filter[i]])))\n",
        "\n",
        "        # define task specific layers\n",
        "        self.pred_task1 = nn.Sequential(nn.Conv2d(in_channels=filter[0], out_channels=filter[0], kernel_size=3, padding=1),\n",
        "                                        nn.Conv2d(in_channels=filter[0], out_channels=self.class_nb, kernel_size=1, padding=0))\n",
        "        self.pred_task2 = nn.Sequential(nn.Conv2d(in_channels=filter[0], out_channels=filter[0], kernel_size=3, padding=1),\n",
        "                                        nn.Conv2d(in_channels=filter[0], out_channels=1, kernel_size=1, padding=0))\n",
        "        self.pred_task3 = nn.Sequential(nn.Conv2d(in_channels=filter[0], out_channels=filter[0], kernel_size=3, padding=1),\n",
        "                                        nn.Conv2d(in_channels=filter[0], out_channels=3, kernel_size=1, padding=0))\n",
        "\n",
        "        # define pooling and unpooling functions\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.logsigma = nn.Parameter(torch.FloatTensor([-0.5, -0.5, -0.5]))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    # define convolutional block\n",
        "    def conv_layer(self, channel):\n",
        "        if opt.type == 'deep':\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(num_features=channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(in_channels=channel[1], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(num_features=channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(num_features=channel[1]),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        return conv_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        g_encoder, g_decoder, g_maxpool, g_upsampl, indices = ([0] * 5 for _ in range(5))\n",
        "        for i in range(5):\n",
        "            g_encoder[i], g_decoder[-i - 1] = ([0] * 2 for _ in range(2))\n",
        "\n",
        "        # global shared encoder-decoder network\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_encoder[i][0] = self.encoder_block[i](x)\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "            else:\n",
        "                g_encoder[i][0] = self.encoder_block[i](g_maxpool[i - 1])\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_upsampl[i] = self.up_sampling(g_maxpool[-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "            else:\n",
        "                g_upsampl[i] = self.up_sampling(g_decoder[i - 1][-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "\n",
        "        # define task prediction layers\n",
        "        t1_pred = F.log_softmax(self.pred_task1(g_decoder[i][1]), dim=1)\n",
        "        t2_pred = self.pred_task2(g_decoder[i][1])\n",
        "        t3_pred = self.pred_task3(g_decoder[i][1])\n",
        "        t3_pred = t3_pred / torch.norm(t3_pred, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        return [t1_pred, t2_pred, t3_pred], self.logsigma\n",
        "\n",
        "\n",
        "# define model, optimiser and scheduler\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_SPLIT = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_SPLIT.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_SPLIT),\n",
        "                                                         count_parameters(SegNet_SPLIT) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')\n",
        "\n",
        "# define dataset\n",
        "dataset_path = opt.dataroot\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)\n",
        "\n",
        "batch_size = 2\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Train and evaluate multi-task network\n",
        "multi_task_trainer(nyuv2_train_loader,\n",
        "                   nyuv2_test_loader,\n",
        "                   SegNet_SPLIT,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   opt,\n",
        "                   200)"
      ],
      "metadata": {
        "id": "oidq78_DzZgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정리 x"
      ],
      "metadata": {
        "id": "f-SqDYGS0A7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **d) 다중 작업, 밀집(Multi-Task, Dense)**"
      ],
      "metadata": {
        "id": "KZwimX0gzl-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "from create_dataset import *\n",
        "from utils import *\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Multi-task: Dense')\n",
        "parser.add_argument('--weight', default='equal', type=str, help='multi-task weighting: equal, uncert, dwa')\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "parser.add_argument('--temp', default=2.0, type=float, help='temperature for DWA (must be positive)')\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        # initialise network parameters\n",
        "        filter = [64, 128, 256, 512, 512]\n",
        "        self.class_nb = 13\n",
        "\n",
        "        # define encoder decoder layers\n",
        "        self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0], filter[0]], bottle_neck=True)])\n",
        "        self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0], self.class_nb], bottle_neck=True)])\n",
        "\n",
        "        self.encoder_block_t = nn.ModuleList([nn.ModuleList([self.conv_layer([3, filter[0], filter[0]], bottle_neck=True)])])\n",
        "        self.decoder_block_t = nn.ModuleList([nn.ModuleList([self.conv_layer([2 * filter[0], 2 * filter[0], filter[0]], bottle_neck=True)])])\n",
        "\n",
        "        for i in range(4):\n",
        "            if i == 0:\n",
        "                self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1], filter[i + 1]], bottle_neck=True))\n",
        "                self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i], filter[i]], bottle_neck=True))\n",
        "            else:\n",
        "                self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1], filter[i + 1]], bottle_neck=False))\n",
        "                self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i], filter[i]], bottle_neck=False))\n",
        "\n",
        "        for j in range(3):\n",
        "            if j < 2:\n",
        "                self.encoder_block_t.append(nn.ModuleList([self.conv_layer([3, filter[0], filter[0]], bottle_neck=True)]))\n",
        "                self.decoder_block_t.append(nn.ModuleList([self.conv_layer([2 * filter[0], 2 * filter[0], filter[0]], bottle_neck=True)]))\n",
        "            for i in range(4):\n",
        "                if i == 0:\n",
        "                    self.encoder_block_t[j].append(self.conv_layer([2 * filter[i], filter[i + 1], filter[i + 1]], bottle_neck=True))\n",
        "                    self.decoder_block_t[j].append(self.conv_layer([2 * filter[i + 1], filter[i], filter[i]], bottle_neck=True))\n",
        "                else:\n",
        "                    self.encoder_block_t[j].append(self.conv_layer([2 * filter[i], filter[i + 1], filter[i + 1]], bottle_neck=False))\n",
        "                    self.decoder_block_t[j].append(self.conv_layer([2 * filter[i + 1], filter[i], filter[i]], bottle_neck=False))\n",
        "\n",
        "        # define pooling and unpooling functions\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.pred_task1 = self.conv_layer([filter[0], self.class_nb], bottle_neck=True, pred_layer=True)\n",
        "        self.pred_task2 = self.conv_layer([filter[0], 1], bottle_neck=True, pred_layer=True)\n",
        "        self.pred_task3 = self.conv_layer([filter[0], 3], bottle_neck=True, pred_layer=True)\n",
        "\n",
        "        self.logsigma = nn.Parameter(torch.FloatTensor([-0.5, -0.5, -0.5]))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def conv_layer(self, channel, bottle_neck, pred_layer=False):\n",
        "        if bottle_neck:\n",
        "            if not pred_layer:\n",
        "                conv_block = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(channel[1]),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(channel[2]),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                )\n",
        "            else:\n",
        "                conv_block = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(in_channels=channel[1], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[2]),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        return conv_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_conv, decoder_conv, encoder_samp, decoder_samp, indices = ([0] * 5 for _ in range(5))\n",
        "        encoder_conv_t, decoder_conv_t, encoder_samp_t, decoder_samp_t, indices_t = ([0] * 3 for _ in range(5))\n",
        "        for i in range(3):\n",
        "            encoder_conv_t[i], decoder_conv_t[i], encoder_samp_t[i], decoder_samp_t[i], indices_t[i] = ([0] * 5 for _ in range(5))\n",
        "\n",
        "        # global shared encoder-decoder network\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                encoder_conv[i] = self.encoder_block[i](x)\n",
        "                encoder_samp[i], indices[i] = self.down_sampling(encoder_conv[i])\n",
        "            else:\n",
        "                encoder_conv[i] = self.encoder_block[i](encoder_samp[i - 1])\n",
        "                encoder_samp[i], indices[i] = self.down_sampling(encoder_conv[i])\n",
        "\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                decoder_samp[i] = self.up_sampling(encoder_samp[-1], indices[-1])\n",
        "                decoder_conv[i] = self.decoder_block[-i - 1](decoder_samp[i])\n",
        "            else:\n",
        "                decoder_samp[i] = self.up_sampling(decoder_conv[i - 1], indices[-i - 1])\n",
        "                decoder_conv[i] = self.decoder_block[-i - 1](decoder_samp[i])\n",
        "\n",
        "        # define task prediction layers\n",
        "        for j in range(3):\n",
        "            for i in range(5):\n",
        "                if i == 0:\n",
        "                    encoder_conv_t[j][i] = self.encoder_block_t[j][i](x)\n",
        "                    encoder_samp_t[j][i], indices_t[j][i] = self.down_sampling(encoder_conv_t[j][i])\n",
        "                else:\n",
        "                    encoder_conv_t[j][i] = self.encoder_block_t[j][i](torch.cat((encoder_samp_t[j][i - 1], encoder_samp[i - 1]), dim=1))\n",
        "                    encoder_samp_t[j][i], indices_t[j][i] = self.down_sampling(encoder_conv_t[j][i])\n",
        "\n",
        "            for i in range(5):\n",
        "                if i == 0:\n",
        "                    decoder_samp_t[j][i] = self.up_sampling(encoder_samp_t[j][-1], indices_t[j][-1])\n",
        "                    decoder_conv_t[j][i] = self.decoder_block_t[j][-i - 1](torch.cat((decoder_samp_t[j][i], decoder_samp[i]), dim=1))\n",
        "                else:\n",
        "                    decoder_samp_t[j][i] = self.up_sampling(decoder_conv_t[j][i - 1], indices_t[j][-i - 1])\n",
        "                    decoder_conv_t[j][i] = self.decoder_block_t[j][-i - 1](torch.cat((decoder_samp_t[j][i], decoder_samp[i]), dim=1))\n",
        "\n",
        "        t1_pred = F.log_softmax(self.pred_task1(decoder_conv_t[0][-1]), dim=1)\n",
        "        t2_pred = self.pred_task2(decoder_conv_t[1][-1])\n",
        "        t3_pred = self.pred_task3(decoder_conv_t[2][-1])\n",
        "        t3_pred = t3_pred / torch.norm(t3_pred, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        return [t1_pred, t2_pred, t3_pred], self.logsigma\n",
        "\n",
        "\n",
        "# define model, optimiser and scheduler\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_DENSE = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_DENSE.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_DENSE),\n",
        "                                                         count_parameters(SegNet_DENSE) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')\n",
        "\n",
        "# define dataset\n",
        "dataset_path = opt.dataroot\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)\n",
        "\n",
        "batch_size = 2\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Train and evaluate multi-task network\n",
        "multi_task_trainer(nyuv2_train_loader,\n",
        "                   nyuv2_test_loader,\n",
        "                   SegNet_DENSE,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   opt,\n",
        "                   200)"
      ],
      "metadata": {
        "id": "nsDTvnuHzr6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정리 x"
      ],
      "metadata": {
        "id": "imbb_4PV0Guw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **e) 다중 작업, 크로스 스티치(Multi-Task, Cross-stitch)**"
      ],
      "metadata": {
        "id": "GPMXBrHWzsMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "from create_dataset import *\n",
        "from utils import *\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Multi-task: Cross')\n",
        "parser.add_argument('--weight', default='equal', type=str, help='multi-task weighting: equal, uncert, dwa')\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "parser.add_argument('--temp', default=2.0, type=float, help='temperature for DWA (must be positive)')\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        # initialise network parameters\n",
        "        filter = [64, 128, 256, 512, 512]\n",
        "        self.class_nb = 13\n",
        "\n",
        "        # define encoder decoder layers\n",
        "        self.encoder_block_t = nn.ModuleList([nn.ModuleList([self.conv_layer([3, filter[0], filter[0]], bottle_neck=True)])])\n",
        "        self.decoder_block_t = nn.ModuleList([nn.ModuleList([self.conv_layer([filter[0], filter[0], filter[0]], bottle_neck=True)])])\n",
        "\n",
        "        for j in range(3):\n",
        "            if j < 2:\n",
        "                self.encoder_block_t.append(nn.ModuleList([self.conv_layer([3, filter[0], filter[0]], bottle_neck=True)]))\n",
        "                self.decoder_block_t.append(nn.ModuleList([self.conv_layer([filter[0], filter[0], filter[0]], bottle_neck=True)]))\n",
        "            for i in range(4):\n",
        "                if i == 0:\n",
        "                    self.encoder_block_t[j].append(self.conv_layer([filter[i], filter[i + 1], filter[i + 1]], bottle_neck=True))\n",
        "                    self.decoder_block_t[j].append(self.conv_layer([filter[i + 1], filter[i], filter[i]], bottle_neck=True))\n",
        "                else:\n",
        "                    self.encoder_block_t[j].append(self.conv_layer([filter[i], filter[i + 1], filter[i + 1]], bottle_neck=False))\n",
        "                    self.decoder_block_t[j].append(self.conv_layer([filter[i + 1], filter[i], filter[i]], bottle_neck=False))\n",
        "\n",
        "        # define cross-stitch units\n",
        "        self.cs_unit_encoder = nn.Parameter(data=torch.ones(4, 3))\n",
        "        self.cs_unit_decoder = nn.Parameter(data=torch.ones(5, 3))\n",
        "\n",
        "        # define task specific layers\n",
        "        self.pred_task1 = self.conv_layer([filter[0], self.class_nb], bottle_neck=True, pred_layer=True)\n",
        "        self.pred_task2 = self.conv_layer([filter[0], 1], bottle_neck=True, pred_layer=True)\n",
        "        self.pred_task3 = self.conv_layer([filter[0], 3], bottle_neck=True, pred_layer=True)\n",
        "\n",
        "        # define pooling and unpooling functions\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.logsigma = nn.Parameter(torch.FloatTensor([-0.5, -0.5, -0.5]))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Parameter):\n",
        "                nn.init.constant(m.weight, 1)\n",
        "\n",
        "    def conv_layer(self, channel, bottle_neck, pred_layer=False):\n",
        "        if bottle_neck:\n",
        "            if not pred_layer:\n",
        "                conv_block = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(channel[1]),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(channel[2]),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                )\n",
        "            else:\n",
        "                conv_block = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "                    nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(in_channels=channel[1], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(channel[2]),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        return conv_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_conv_t, decoder_conv_t, encoder_samp_t, decoder_samp_t, indices_t = ([0] * 3 for _ in range(5))\n",
        "        for i in range(3):\n",
        "            encoder_conv_t[i], decoder_conv_t[i], encoder_samp_t[i], decoder_samp_t[i], indices_t[i] = ([0] * 5 for _ in range(5))\n",
        "\n",
        "        # task branch 1\n",
        "        for i in range(5):\n",
        "            for j in range(3):\n",
        "                if i == 0:\n",
        "                    encoder_conv_t[j][i] = self.encoder_block_t[j][i](x)\n",
        "                    encoder_samp_t[j][i], indices_t[j][i] = self.down_sampling(encoder_conv_t[j][i])\n",
        "                else:\n",
        "                    encoder_cross_stitch = self.cs_unit_encoder[i - 1][0] * encoder_samp_t[0][i - 1] + \\\n",
        "                                           self.cs_unit_encoder[i - 1][1] * encoder_samp_t[1][i - 1] + \\\n",
        "                                           self.cs_unit_encoder[i - 1][2] * encoder_samp_t[2][i - 1]\n",
        "                    encoder_conv_t[j][i] = self.encoder_block_t[j][i](encoder_cross_stitch)\n",
        "                    encoder_samp_t[j][i], indices_t[j][i] = self.down_sampling(encoder_conv_t[j][i])\n",
        "\n",
        "        for i in range(5):\n",
        "            for j in range(3):\n",
        "                if i == 0:\n",
        "                    decoder_cross_stitch = self.cs_unit_decoder[i][0] * encoder_samp_t[0][-1] + \\\n",
        "                                           self.cs_unit_decoder[i][1] * encoder_samp_t[1][-1] + \\\n",
        "                                           self.cs_unit_decoder[i][2] * encoder_samp_t[2][-1]\n",
        "                    decoder_samp_t[j][i] = self.up_sampling(decoder_cross_stitch, indices_t[j][-i - 1])\n",
        "                    decoder_conv_t[j][i] = self.decoder_block_t[j][-i - 1](decoder_samp_t[j][i])\n",
        "                else:\n",
        "                    decoder_cross_stitch = self.cs_unit_decoder[i][0] * decoder_conv_t[0][i - 1] + \\\n",
        "                                           self.cs_unit_decoder[i][1] * decoder_conv_t[1][i - 1] + \\\n",
        "                                           self.cs_unit_decoder[i][2] * decoder_conv_t[2][i - 1]\n",
        "                    decoder_samp_t[j][i] = self.up_sampling(decoder_cross_stitch, indices_t[j][-i - 1])\n",
        "                    decoder_conv_t[j][i] = self.decoder_block_t[j][-i - 1](decoder_samp_t[j][i])\n",
        "\n",
        "        # define task prediction layers\n",
        "        t1_pred = F.log_softmax(self.pred_task1(decoder_conv_t[0][-1]), dim=1)\n",
        "        t2_pred = self.pred_task2(decoder_conv_t[1][-1])\n",
        "        t3_pred = self.pred_task3(decoder_conv_t[2][-1])\n",
        "        t3_pred = t3_pred / torch.norm(t3_pred, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        return [t1_pred, t2_pred, t3_pred], self.logsigma\n",
        "\n",
        "\n",
        "# define model, optimiser and scheduler\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_CROSS = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_CROSS.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_CROSS),\n",
        "                                                         count_parameters(SegNet_CROSS) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')\n",
        "\n",
        "# define dataset\n",
        "dataset_path = opt.dataroot\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)\n",
        "\n",
        "batch_size = 2\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Train and evaluate multi-task network\n",
        "multi_task_trainer(nyuv2_train_loader,\n",
        "                   nyuv2_test_loader,\n",
        "                   SegNet_CROSS,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   opt,\n",
        "                   200)"
      ],
      "metadata": {
        "id": "0YFhkqYDzx3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정리 x"
      ],
      "metadata": {
        "id": "Uj-89m6w0OcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-3. 최종 목표**\n",
        "- MTAN(Multi-task Attention Network)"
      ],
      "metadata": {
        "id": "2fclS8jjzyA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **📌 전체 Process**\n",
        "1. **네트워크 파라미터 초기화**\n",
        "- 모델 내부에서 사용되는 ```필터 개수``` 및 ```클래스 수```와 같은 네트워크 파라미터를 초기화\n",
        "\n",
        "2. **인코더와 디코더 레이어 정의**\n",
        "- SegNet은 인코더와 디코더로 구성되며, 이 레이어들은 이미지의 특징을 추출하고 다시 복원\n",
        "- 각 레이어는 ```컨볼루션 레이어```, ```배치 정규화``` 및 ```ReLU``` 활성화 함수로 구성\n",
        "- Encoder는 이미지를 down-sampling하고 Decoder는 up-sampling 함\n",
        "\n",
        "3. **컨볼루션 레이어 정의**\n",
        "- 인코더와 디코더에서 사용되는 컨볼루션 레이어를 정의\n",
        "- 이미지 특징 추출, 세분화된 예측을 생성하는 데 사용\n",
        "\n",
        "4. **어텐션 레이어 정의**\n",
        "- 어텐션 레이어는 다양한 작업 간에 특징을 공유하도록 함\n",
        "- 각 어텐션 레이어는 ```컨볼루션 레이어```와 ```시그모이드``` 활성화 함수로 구성되며, 작업 간의 상호 작용을 조절하는 데 사용\n",
        "\n",
        "5. **풀링 및 언풀링 함수 정의**\n",
        "- pooling 레이어는 이미지를 down-sampling하고, unpooling 레이어는 up-sampling\n",
        "- 이미지 크기를 조절하고 공간적인 정보를 보존하는 데 사용\n",
        "\n",
        "6. **가중치 초기화**\n",
        "- 모든 레이어의 가중치와 편향을 초기화\n",
        "  - 모델이 효과적으로 학습될 수 있도록 함\n",
        "\n",
        "7. **순전파 함수 정의**\n",
        "- 네트워크의 입력부터 출력까지의 데이터 흐름을 정의\n",
        "- 해당 코드는 ```MTAN(Multi-Task Attention Network)``` 아키텍처를 구현\n",
        "  - 다중 작업을 수행하도록 네트워크를 구성\n",
        "  - Encoder와 Decoder를 통해 특징을 추출하고 어텐션 메커니즘을 사용하여 작업 간에 정보를 공유\n",
        "  - 각 작업에 대한 예측 레이어를 정의하고, 마지막으로 클래스 확률 예측을 수행"
      ],
      "metadata": {
        "id": "GMk4Xv_UYHNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Import Libraries\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "from create_dataset import *\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "CA23Qjay3iPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### argparse를 사용하여 명령행 인수를 파싱\n",
        "\n",
        "import argparse\n",
        "\n",
        "# argparse.ArgumentParser를 사용하여 명령행 인수 파서를 생성\n",
        "parser = argparse.ArgumentParser(description='Multi-task: Attention Network')\n",
        "# 명령행 인수를 정의\n",
        "parser.add_argument('--weight', default='equal', type=str, help='multi-task weighting: equal, uncert, dwa')\n",
        "# '--dataroot' 설정\n",
        "parser.add_argument('--dataroot', default='nyuv2', type=str, help='dataset root')\n",
        "parser.add_argument('--temp', default=2.0, type=float, help='temperature for DWA (must be positive)')\n",
        "parser.add_argument('--apply_augmentation', action='store_true', help='toggle to apply data augmentation on NYUv2')\n",
        "# 명령행 인수를 파싱하고 결과를 'opt' 객체에 저장합니다.\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "R4cusHtMz6br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SegNet 클래스 정의\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        # 1. 네트워크 파라미터 초기화\n",
        "        filter = [64, 128, 256, 512, 512]  # 각 레이어의 필터 개수\n",
        "        self.class_nb = 13  # 클래스 개수\n",
        "\n",
        "        # 2. 인코더 및 디코더 레이어 정의\n",
        "        # 이미지의 특징을 추출하고 다시 복원\n",
        "        self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0]])]) # 이미지를 down-sampling\n",
        "        self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0]])]) # 이미지를 up-sampling\n",
        "        for i in range(4):\n",
        "            self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1]]))\n",
        "            self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "\n",
        "        # 3. 컨볼루션 레이어 정의\n",
        "        # Encoder와 Decoder에서 사용되는 합성곱 layer를 정의\n",
        "        self.conv_block_enc = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        self.conv_block_dec = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        for i in range(4):\n",
        "            if i == 0:\n",
        "                self.conv_block_enc.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "                self.conv_block_dec.append(self.conv_layer([filter[i], filter[i]]))\n",
        "            else:\n",
        "                self.conv_block_enc.append(nn.Sequential(self.conv_layer([filter[i + 1], filter[i + 1]]),\n",
        "                                                         self.conv_layer([filter[i + 1], filter[i + 1]])))\n",
        "                self.conv_block_dec.append(nn.Sequential(self.conv_layer([filter[i], filter[i]]),\n",
        "                                                         self.conv_layer([filter[i], filter[i]])))\n",
        "\n",
        "        # 4. task attention 레이어 정의\n",
        "        # 다양한 작업 간에 특징을 공유할 수 있도록 함\n",
        "        self.encoder_att = nn.ModuleList([nn.ModuleList([self.att_layer([filter[0], filter[0], filter[0]])])])\n",
        "        self.decoder_att = nn.ModuleList([nn.ModuleList([self.att_layer([2 * filter[0], filter[0], filter[0]])])])\n",
        "\n",
        "        self.encoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[1]])])\n",
        "        self.decoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "\n",
        "        for j in range(3):\n",
        "            if j < 2:\n",
        "                self.encoder_att.append(nn.ModuleList([self.att_layer([filter[0], filter[0], filter[0]])]))\n",
        "                self.decoder_att.append(nn.ModuleList([self.att_layer([2 * filter[0], filter[0], filter[0]])]))\n",
        "            for i in range(4):\n",
        "                self.encoder_att[j].append(self.att_layer([2 * filter[i + 1], filter[i + 1], filter[i + 1]]))\n",
        "                self.decoder_att[j].append(self.att_layer([filter[i + 1] + filter[i], filter[i], filter[i]]))\n",
        "\n",
        "        for i in range(4):\n",
        "            if i < 3:\n",
        "                self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 2]]))\n",
        "                self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "            else:\n",
        "                self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "                self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "\n",
        "        # 태스크 예측 레이어 정의\n",
        "        # 마지막 레이어인 경우 1*1 convolution을 통해 클래스에 대한 예측 수행\n",
        "        self.pred_task1 = self.conv_layer([filter[0], self.class_nb], pred=True)\n",
        "        self.pred_task2 = self.conv_layer([filter[0], 1], pred=True)\n",
        "        self.pred_task3 = self.conv_layer([filter[0], 3], pred=True)\n",
        "\n",
        "        # 5. 풀링 및 언풀링 함수 정의\n",
        "        # 이미지 크기 조절, 공간 정보 보존\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 풀링 -> down-sampling\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2) # 언풀링 -> up-sampling\n",
        "        self.logsigma = nn.Parameter(torch.FloatTensor([-0.5, -0.5, -0.5]))\n",
        "\n",
        "        # 6. 가중치 초기화\n",
        "        # 모든 모듈의 가중치 및 편향을 적절하게 초기화\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    ## 컨볼루션 레이어 정의\n",
        "    # channel: 입력 및 출력 채널의 수\n",
        "    # pred: 마지막 레이어인지의 여부\n",
        "    def conv_layer(self, channel, pred=False):\n",
        "        if not pred:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(num_features=channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            )\n",
        "        return conv_block\n",
        "\n",
        "    ## 어텐션 레이어 정의\n",
        "    # 입력 채널에서 attention 가중치 생성\n",
        "    def att_layer(self, channel):\n",
        "        att_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[2]),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        return att_block\n",
        "\n",
        "    ## 7. 순전파 함수\n",
        "    # 네트워크의 모든 구성 요소를 초기화하고 데이터가 앞으로 흐르게 됨\n",
        "    def forward(self, x):\n",
        "        # 네트워크의 각 부분을 초기화\n",
        "        g_encoder, g_decoder, g_maxpool, g_upsampl, indices = ([0] * 5 for _ in range(5))\n",
        "        for i in range(5):\n",
        "            g_encoder[i], g_decoder[-i - 1] = ([0] * 2 for _ in range(2))\n",
        "\n",
        "        # 태스크를 위한 어텐션 리스트 정의\n",
        "        atten_encoder, atten_decoder = ([0] * 3 for _ in range(2))\n",
        "        for i in range(3):\n",
        "            atten_encoder[i], atten_decoder[i] = ([0] * 5 for _ in range(2))\n",
        "        for i in range(3):\n",
        "            for j in range(5):\n",
        "                atten_encoder[i][j], atten_decoder[i][j] = ([0] * 3 for _ in range(2))\n",
        "\n",
        "        # 전역 공유 네트워크 정의\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_encoder[i][0] = self.encoder_block[i](x)\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "            else:\n",
        "                g_encoder[i][0] = self.encoder_block[i](g_maxpool[i - 1])\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_upsampl[i] = self.up_sampling(g_maxpool[-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "            else:\n",
        "                g_upsampl[i] = self.up_sampling(g_decoder[i - 1][-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "\n",
        "        # 태스크 종속 어텐션 모듈 정의\n",
        "        # 각 작업 관련 특징 학습\n",
        "        for i in range(3):\n",
        "            for j in range(5):\n",
        "                if j == 0:\n",
        "                    atten_encoder[i][j][0] = self.encoder_att[i][j](g_encoder[j][0])\n",
        "                    atten_encoder[i][j][1] = (atten_encoder[i][j][0]) * g_encoder[j][1]\n",
        "                    atten_encoder[i][j][2] = self.encoder_block_att[j](atten_encoder[i][j][1])\n",
        "                    atten_encoder[i][j][2] = F.max_pool2d(atten_encoder[i][j][2], kernel_size=2, stride=2)\n",
        "                else:\n",
        "                    atten_encoder[i][j][0] = self.encoder_att[i][j](torch.cat((g_encoder[j][0], atten_encoder[i][j - 1][2]), dim=1))\n",
        "                    atten_encoder[i][j][1] = (atten_encoder[i][j][0]) * g_encoder[j][1]\n",
        "                    atten_encoder[i][j][2] = self.encoder_block_att[j](atten_encoder[i][j][1])\n",
        "                    atten_encoder[i][j][2] = F.max_pool2d(atten_encoder[i][j][2], kernel_size=2, stride=2)\n",
        "\n",
        "            for j in range(5):\n",
        "                if j == 0:\n",
        "                    atten_decoder[i][j][0] = F.interpolate(atten_encoder[i][-1][-1], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "                    atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "                    atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "                    atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "                else:\n",
        "                    atten_decoder[i][j][0] = F.interpolate(atten_decoder[i][j - 1][2], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "                    atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "                    atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "                    atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "\n",
        "        # 태스크 예측 레이어 정의\n",
        "        t1_pred = F.log_softmax(self.pred_task1(atten_decoder[0][-1][-1]), dim=1)\n",
        "        t2_pred = self.pred_task2(atten_decoder[1][-1][-1])\n",
        "        t3_pred = self.pred_task3(atten_decoder[2][-1][-1])\n",
        "        t3_pred = t3_pred / torch.norm(t3_pred, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        return [t1_pred, t2_pred, t3_pred], self.logsigma"
      ],
      "metadata": {
        "id": "Lnrdrjnt3sB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델, optimizer 및 scheduler 정의\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_MTAN = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_MTAN.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "# 네트워크의 파라미터 수 출력\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_MTAN),\n",
        "                                                         count_parameters(SegNet_MTAN) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')"
      ],
      "metadata": {
        "id": "V9Bq5J9CSSTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터셋 정의\n",
        "dataset_path = opt.dataroot\n",
        "if opt.apply_augmentation:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)"
      ],
      "metadata": {
        "id": "N_ErqOa04cF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "\n",
        "### 데이터로더 정의\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "7tgB5nDESaS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-task 네트워크를 훈련하고 평가\n",
        "multi_task_trainer(nyuv2_train_loader,\n",
        "                   nyuv2_test_loader,\n",
        "                   SegNet_MTAN,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   opt,\n",
        "                   200)"
      ],
      "metadata": {
        "id": "4E15x1HwSeKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}